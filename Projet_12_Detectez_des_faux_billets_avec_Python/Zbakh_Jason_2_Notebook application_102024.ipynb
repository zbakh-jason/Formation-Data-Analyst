{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: black; padding: 20px; text-align:center\">\n",
    "    <img src=\"image/openclassrooms.png\" alt=\"OpenClassrooms\" style=\"display:block; margin: 0 auto; width: 300px;\"><br>  \n",
    "    <span style=\"font-size: 36px; font-family: 'Lucida Console', Monaco, monospace; font-weight: bold; color: white;display: block;\">\n",
    "        PROJET n°12 : Détectez des faux billets avec R ou <img src=\"image/python.png\" alt=\"Python\" style=\"width: auto; height: 36px; vertical-align:middle;\"> <!-- Hauteur fixe pour Python, aligné au texte -->\n",
    "    </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: black; padding: 20px;\">\n",
    "<span style=\"display: flex; margin: auto; font-size: 36px; font-family: 'Lucida Console', Monaco, monospace; font-weight: bold; color: white;\">\n",
    "\n",
    "</span>\n",
    "\n",
    "* [<span style=\"margin: auto; color: #39FF14; font-size: 28px; font-family: 'Lucida Console', Monaco, monospace; font-weight: bold;\">5 - APPLICATION FONCTIONNELLE</span>](#chapter5)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibliothèques standards\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# Assurez-vous que les bibliothèques suivantes sont installées :\n",
    "# - numpy\n",
    "# - pandas\n",
    "# - joblib\n",
    "\n",
    "# Configuration du chemin pour les modèles\n",
    "if not os.path.exists('models'):\n",
    "    raise FileNotFoundError(\"Le répertoire 'models' contenant les modèles sauvegardés n'existe pas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PRÉDICTIONS SUR NOUVELLES DONNÉES ===\n",
    "\n",
    "def predict_production(data_path, model_name='random_forest'):\n",
    "    \"\"\"\n",
    "    Fait des prédictions sur de nouvelles données.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Lire les données avec le séparateur correct\n",
    "        new_data = pd.read_csv(data_path, sep=',')  # séparateur virgule pour les données de production\n",
    "        print(f\"Données chargées : {len(new_data)} lignes\")\n",
    "        \n",
    "        # Définir l'ordre exact des features comme dans l'entraînement\n",
    "        base_features = ['diagonal', 'height_left', 'height_right', 'margin_low', 'margin_up', 'length']\n",
    "        \n",
    "        print(\"\\nVérification des colonnes :\")\n",
    "        print(\"Colonnes attendues :\", base_features)\n",
    "        print(\"Colonnes présentes :\", new_data.columns.tolist())\n",
    "        \n",
    "        # Vérifier la présence de toutes les colonnes nécessaires\n",
    "        for feature in base_features:\n",
    "            if feature not in new_data.columns:\n",
    "                raise ValueError(f\"Colonne manquante : {feature}\")\n",
    "        \n",
    "        # Créer les features dérivées\n",
    "        print(\"\\nCréation des features dérivées...\")\n",
    "        new_data['height_ratio'] = new_data['height_left'] / new_data['height_right']\n",
    "        new_data['margin_ratio'] = new_data['margin_up'] / new_data['margin_low']\n",
    "        new_data['diagonal_length_ratio'] = new_data['diagonal'] / new_data['length']\n",
    "        \n",
    "        # Sélectionner et ordonner les features dans le même ordre que l'entraînement\n",
    "        features = base_features + ['height_ratio', 'margin_ratio', 'diagonal_length_ratio']\n",
    "        X = new_data[features]\n",
    "        \n",
    "        print(\"\\nDimensions des données avant scaling :\", X.shape)\n",
    "        \n",
    "        # Charger le scaler et normaliser les données\n",
    "        scaler = joblib.load(os.path.join('models', 'scaler.pkl'))\n",
    "        X_scaled = scaler.transform(X)\n",
    "        print(\"Dimensions des données après scaling :\", X_scaled.shape)\n",
    "        \n",
    "        # Charger le modèle et faire les prédictions\n",
    "        model = joblib.load(os.path.join('models', model_name, f\"{model_name}.pkl\"))\n",
    "        predictions = model.predict(X_scaled)\n",
    "        probabilities = model.predict_proba(X_scaled)\n",
    "        \n",
    "        # Créer le DataFrame des résultats\n",
    "        results = pd.DataFrame({\n",
    "            'ID': new_data['id'],\n",
    "            'Prédiction': predictions,\n",
    "            'Classe': ['Authentique' if p == 1 else 'Contrefaçon' for p in predictions],\n",
    "            'Probabilité_Authentique': [f\"{prob:.1f}%\" for prob in (probabilities[:, 1] * 100)]\n",
    "        })\n",
    "        \n",
    "        # Afficher résumé\n",
    "        print(\"\\n=== RÉSUMÉ DES PRÉDICTIONS ===\")\n",
    "        print(f\"Nombre total de billets : {len(results)}\")\n",
    "        \n",
    "        authentiques = (results['Classe'] == 'Authentique').sum()\n",
    "        contrefaits = (results['Classe'] == 'Contrefaçon').sum()\n",
    "        \n",
    "        print(f\"\\nBillets authentiques : {authentiques} ({authentiques/len(results)*100:.1f}%)\")\n",
    "        auth_results = results[results['Classe'] == 'Authentique']\n",
    "        print(\"\\nDétail des billets authentiques :\")\n",
    "        print(auth_results[['ID', 'Probabilité_Authentique']].to_string(index=False))\n",
    "        \n",
    "        print(f\"\\nBillets contrefaits : {contrefaits} ({contrefaits/len(results)*100:.1f}%)\")\n",
    "        print(\"\\nDétail des billets contrefaits :\")\n",
    "        fake_results = results[results['Classe'] == 'Contrefaçon']\n",
    "        print(fake_results[['ID', 'Probabilité_Authentique']].to_string(index=False))\n",
    "        \n",
    "        print(\"\\n=== RÉSULTATS COMPLETS ===\")\n",
    "        print(results.to_string(index=False))\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Une erreur s'est produite : {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données chargées : 5 lignes\n",
      "\n",
      "Vérification des colonnes :\n",
      "Colonnes attendues : ['diagonal', 'height_left', 'height_right', 'margin_low', 'margin_up', 'length']\n",
      "Colonnes présentes : ['diagonal', 'height_left', 'height_right', 'margin_low', 'margin_up', 'length', 'id']\n",
      "\n",
      "Création des features dérivées...\n",
      "\n",
      "Dimensions des données avant scaling : (5, 9)\n",
      "Dimensions des données après scaling : (5, 9)\n",
      "\n",
      "=== RÉSUMÉ DES PRÉDICTIONS ===\n",
      "Nombre total de billets : 5\n",
      "\n",
      "Billets authentiques : 2 (40.0%)\n",
      "\n",
      "Détail des billets authentiques :\n",
      " ID Probabilité_Authentique\n",
      "A_4                  100.0%\n",
      "A_5                  100.0%\n",
      "\n",
      "Billets contrefaits : 3 (60.0%)\n",
      "\n",
      "Détail des billets contrefaits :\n",
      " ID Probabilité_Authentique\n",
      "A_1                   -0.0%\n",
      "A_2                   -0.0%\n",
      "A_3                   -0.0%\n",
      "\n",
      "=== RÉSULTATS COMPLETS ===\n",
      " ID  Prédiction      Classe Probabilité_Authentique\n",
      "A_1           0 Contrefaçon                   -0.0%\n",
      "A_2           0 Contrefaçon                   -0.0%\n",
      "A_3           0 Contrefaçon                   -0.0%\n",
      "A_4           1 Authentique                  100.0%\n",
      "A_5           1 Authentique                  100.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\mamba\\envs\\Mamba_GPU_3_9\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\mamba\\envs\\Mamba_GPU_3_9\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Utilisation\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    data_path = 'billets_production.csv'  # Remplacez par le chemin de votre fichier de données\n",
    "\n",
    "    predictions = predict_production(data_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
